{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language(path, name) is deprecated. Use Language(ptr, name) instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pysqlite3\n",
    "\n",
    "sys.modules['sqlite3'] = pysqlite3\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import ollama\n",
    "from functools import cached_property\n",
    "from langchain_community.llms import AzureOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader,TextLoader\n",
    "from langchain_text_splitters import (Language,RecursiveCharacterTextSplitter)\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import requests\n",
    "import voyageai\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_voyageai import VoyageAIEmbeddings,VoyageAIRerank\n",
    "from tree_sitter_languages import get_language, get_parser\n",
    "from llama_index.core.text_splitter import CodeSplitter\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "\n",
    "from chunker import get_code_chunks\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "def doc_merger(splits):\n",
    "    current = 0\n",
    "    while True:\n",
    "        doc_lines = len(splits[current].splitlines())\n",
    "        if doc_lines < 3:\n",
    "            # merge with next doc\n",
    "            splits[current] += splits[current + 1]\n",
    "            splits.pop(current + 1)\n",
    "        else:\n",
    "            current += 1\n",
    "        \n",
    "        if current == len(splits) - 1:\n",
    "            return splits\n",
    "\n",
    "command = [\"clang-format\",\"-style={ColumnLimit: 300, AllowShortFunctionsOnASingleLine: All, AllowShortIfStatementsOnASingleLine: true}\",\"-i\",\"original.txt\"]\n",
    "\n",
    "subprocess.run(command, check=True)\n",
    "\n",
    "file_path = \"original.txt\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    docs = f.read()\n",
    "\n",
    "splits = get_code_chunks(docs)\n",
    "new_splits = [split for split in splits if len(split) > 2]\n",
    "new_splits2 = doc_merger(new_splits)\n",
    "# documents = [Document(page_content=split) for split in splits]\n",
    "documents = [Document(page_content=split) for split in new_splits2]\n",
    "# save documents to files\n",
    "# for i, doc in enumerate(documents):\n",
    "#     with open(f\"docs/doc_{i}.txt\", \"w\") as f:\n",
    "#         f.write(doc.page_content)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "db = Chroma.from_documents(documents=documents, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"Snippet.{i+1}:\\n\\n{doc.page_content}\" for i, doc in enumerate(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe = [\n",
    "{\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\",\n",
    "},\n",
    "{\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_NONE\",\n",
    "},\n",
    "{\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_NONE\",\n",
    "},\n",
    "{\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\",\n",
    "},\n",
    "]\n",
    "genai.configure(api_key=os.environ.get(\"GENAI_API_KEY\"))\n",
    "generation_config = {\n",
    "\"temperature\": 0.1,\n",
    "\"top_p\": 0.95,\n",
    "\"top_k\": 64,\n",
    "\"max_output_tokens\": 8192,\n",
    "\"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "model_name=\"gemini-1.5-flash\",\n",
    "generation_config=generation_config,\n",
    "safety_settings = safe\n",
    ")\n",
    "llm = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "def call_retrieval_sada(pretext, fifty_clean):\n",
    "\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "    retrieved_docs = retriever.invoke(pretext)\n",
    "\n",
    "    formatted_context = combine_docs(retrieved_docs)\n",
    "\n",
    "    formatted_context_2 = \"Snippet.0: \\n\\n\" + fifty_clean + \"\\n\\n\" + formatted_context\n",
    "\n",
    "    return formatted_context_2\n",
    "\n",
    "    # return formatted_context, [], retrieved_docs, []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your cand sets below\n",
    "\n",
    "##### Add `Pretext`, `Fifty_Text` and `Query` as variables\n",
    "\n",
    "##### Original.txt, prompt, and sec_list must be in `manual_testing/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESPONSE:\n",
      " Class 1: This code is not directly involved in multi-threading, input processing, sorting, or output. It's part of the merging logic, which is a step in the sorting process, but not the core functionality itself.\n",
      "Class 2: This code is not strictly necessary for the basic sorting functionality. It handles a specific edge case during merging, where the number of files to be merged doesn't divide evenly by the number of merge slots.\n",
      "Class 3: This code is necessary for the efficient and correct merging of sorted files. It ensures that all files are merged in a way that minimizes the number of temporary files created and optimizes the merging process.\n",
      "Class 4: This code is not critical for the program's functionality. The program would still function without it, albeit with potentially less efficient merging.\n",
      "Class 5: The context provided is sufficient to understand the purpose of this code. It's part of the merging logic within the sorting process.\n",
      "Class 6: This code is used in the provided context. It's part of the `merge` function, which is called during the sorting process.\n",
      "\n",
      "Explanation: The code snippet is part of the `merge` function, which is responsible for merging multiple sorted temporary files into a single sorted output file. This specific code handles a scenario where the number of files to be merged doesn't divide evenly by the number of merge slots. It ensures that all files are merged efficiently and correctly, contributing to the overall sorting process. While not strictly necessary for the basic sorting functionality, it optimizes the merging process and improves the program's efficiency.\n",
      "\n",
      "Final Verdict: Class 3 (Necessary Code) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = model.start_chat(history=[])\n",
    "\n",
    "with open('prompt_in_coverage.txt', 'r') as file:\n",
    "    prompt_template = file.read()\n",
    "\n",
    "with open('sec_list.txt', 'r') as file:\n",
    "    sec_list = file.read()\n",
    "\n",
    "\n",
    "pretext = \"\"\"\n",
    "        }\n",
    "        ntemps -= tmp___2;\n",
    "        (files + out)->name = (char const *)(temp->name);\n",
    "        (files + out)->temp = temp;\n",
    "        in += num_merged;\n",
    "        out++;\n",
    "      }\n",
    "    while_break___0:\n",
    "      remainder = nfiles - in;\n",
    "      cheap_slots = (unsigned long)nmerge - out % (unsigned long)nmerge;\n",
    "      if (cheap_slots < remainder) {\n",
    "        nshortmerge = (remainder - cheap_slots) + 1UL;\n",
    "        tmp___3 = create_temp(&tfp___0);\n",
    "        temp___0 = tmp___3;\n",
    "        if (ntemps < nshortmerge) {\n",
    "          tmp___4 = ntemps;\n",
    "        } else {\n",
    "          tmp___4 = nshortmerge;\n",
    "        }\n",
    "        tmp___5 = mergefiles(files + in, tmp___4, nshortmerge, tfp___0, (char const *)(temp___0->name));\n",
    "        num_merged___0 = tmp___5;\n",
    "        if (ntemps < num_merged___0) {\n",
    "          tmp___6 = ntemps;\n",
    "        } else {\n",
    "          tmp___6 = num_merged___0;\n",
    "        }\n",
    "        ntemps -= tmp___6;\n",
    "        (files + out)->name = (char const *)(temp___0->name);\n",
    "        tmp___7 = out;\n",
    "        out++;\n",
    "        (files + tmp___7)->temp = temp___0;\n",
    "        in += num_merged___0;\n",
    "      }\n",
    "      memmove((void *)(files + out), (void const *)(files + in), (nfiles - in) * sizeof(*files));\n",
    "      ntemps += out;\n",
    "      nfiles -= in - out;\n",
    "    }\n",
    "  while_break:\n",
    "    avoid_trashing_input(files, ntemps, nfiles, output_file);\n",
    "    while (1) {\n",
    "      tmp___8 = open_input_files(files, nfiles, &fps);\n",
    "      nopened = tmp___8;\n",
    "      \n",
    "static void sort(char *const *files, size_t nfiles, char const *output_file, size_t nthreads) {\n",
    "  struct buffer buf___1;\n",
    "  size_t ntemps;\n",
    "  _Bool output_file_created;\n",
    "  char const *temp_output;\n",
    "  char const *file;\"\"\"\n",
    "\n",
    "fifty_clean = \"\"\"\"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "  if (cheap_slots < remainder) {\n",
    "    nshortmerge = (remainder - cheap_slots) + 1UL;\n",
    "    tmp___3 = create_temp(&tfp___0);\n",
    "    temp___0 = tmp___3;\n",
    "    if (ntemps < nshortmerge) {\n",
    "      tmp___4 = ntemps;\n",
    "    } else {\n",
    "      tmp___4 = nshortmerge;\n",
    "    }\n",
    "    tmp___5 = mergefiles(files + in, tmp___4, nshortmerge, tfp___0,\n",
    "                         (char const *)(temp___0->name));\n",
    "    num_merged___0 = tmp___5;\n",
    "    if (ntemps < num_merged___0) {\n",
    "      tmp___6 = ntemps;\n",
    "    } else {\n",
    "      tmp___6 = num_merged___0;\n",
    "    }\n",
    "    ntemps -= tmp___6;\n",
    "    (files + out)->name = (char const *)(temp___0->name);\n",
    "    tmp___7 = out;\n",
    "    out++;\n",
    "    (files + tmp___7)->temp = temp___0;\n",
    "    in += num_merged___0;\n",
    "  }\n",
    "\"\"\"\n",
    "formatted_context = call_retrieval_sada(pretext, fifty_clean)\n",
    "\n",
    "prompt = prompt_template.format(sec_list=sec_list, formatted_context=formatted_context, query=query)\n",
    "response = llm.send_message(prompt).text\n",
    "\n",
    "print(\"\\nRESPONSE:\\n\",response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippet.0: \n",
      "\n",
      "\n",
      "\n",
      "Snippet.1:\n",
      "\n",
      "  }\n",
      "}\n",
      "static size_t mergefiles(struct sortfile *files, size_t ntemps, size_t nfiles, FILE *ofp, char const *output_file) {\n",
      "  FILE **fps;\n",
      "  size_t nopened;\n",
      "  size_t tmp;\n",
      "  char *tmp___0;\n",
      "\n",
      "  {\n",
      "    tmp = open_input_files(files, nfiles, &fps);\n",
      "    nopened = tmp;\n",
      "    if (nopened < nfiles) {\n",
      "      if (nopened < 2UL) {\n",
      "        tmp___0 = gettext(\"open failed\");\n",
      "        die((char const *)tmp___0, (files + nopened)->name);\n",
      "      }\n",
      "    }\n",
      "    mergefps(files, ntemps, nopened, ofp, output_file, fps);\n",
      "    return (nopened);\n",
      "  }\n",
      "}\n",
      "static void mergelines(struct line *__restrict t, size_t nlines, struct line const *__restrict lo) {\n",
      "  size_t nlo;\n",
      "  size_t nhi;\n",
      "  struct line *hi;\n",
      "  int tmp;\n",
      "\n",
      "  {\n",
      "    nlo = nlines / 2UL;\n",
      "    nhi = nlines - nlo;\n",
      "    hi = (struct line *)(t - nlo);\n",
      "    while (1) {\n",
      "      tmp = compare((struct line const *)(lo - 1), (struct line const *)(hi - 1));\n",
      "      if (tmp <= 0) {\n",
      "        t--;\n",
      "        lo--;\n",
      "        *t = (struct line) * lo;\n",
      "        nlo--;\n",
      "        if (!nlo) {\n",
      "          return;\n",
      "        }\n",
      "      } else {\n",
      "        t--;\n",
      "        hi--;\n",
      "        *t = *hi;\n",
      "        nhi--;\n",
      "        if (!nhi) {\n",
      "          while (1) {\n",
      "            t--;\n",
      "            lo--;\n",
      "            *t = (struct line) * lo;\n",
      "            nlo--;\n",
      "            if (!nlo) {\n",
      "              goto while_break___0;\n",
      "            }\n",
      "          }\n",
      "        while_break___0:;\n",
      "          return;\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "\n",
      "    return;\n",
      "  }\n",
      "}\n",
      "\n",
      "Snippet.2:\n",
      "\n",
      "static void sort(char *const *files, size_t nfiles, char const *output_file, size_t nthreads) {\n",
      "  struct buffer buf___1;\n",
      "  size_t ntemps;\n",
      "  _Bool output_file_created;\n",
      "  char const *temp_output;\n",
      "  char const *file;\n",
      "  FILE *fp;\n",
      "  FILE *tmp;\n",
      "  FILE *tfp;\n",
      "  size_t bytes_per_line;\n",
      "  size_t tmp___0;\n",
      "  size_t mult;\n",
      "  size_t tmp___1;\n",
      "  struct line *line;\n",
      "  struct tempnode *tmp___2;\n",
      "  struct merge_node_queue queue;\n",
      "  struct merge_node *merge_tree;\n",
      "  struct merge_node *tmp___3;\n",
      "  struct merge_node *root;\n",
      "  _Bool tmp___4;\n",
      "  size_t i;\n",
      "  struct tempnode *node;\n",
      "  struct sortfile *tempfiles;\n",
      "  struct sortfile *tmp___5;\n",
      "\n",
      "\n",
      "Snippet.3:\n",
      "\n",
      "static void merge(struct sortfile *files, size_t ntemps, size_t nfiles, char const *output_file) {\n",
      "  size_t in;\n",
      "  size_t out;\n",
      "  size_t remainder;\n",
      "  size_t cheap_slots;\n",
      "  FILE *tfp;\n",
      "  struct tempnode *temp;\n",
      "  struct tempnode *tmp;\n",
      "  size_t num_merged;\n",
      "  size_t tmp___0;\n",
      "  size_t tmp___1;\n",
      "  size_t tmp___2;\n",
      "  size_t nshortmerge;\n",
      "  FILE *tfp___0;\n",
      "  struct tempnode *temp___0;\n",
      "  struct tempnode *tmp___3;\n",
      "  size_t num_merged___0;\n",
      "  size_t tmp___4;\n",
      "  size_t tmp___5;\n",
      "  size_t tmp___6;\n",
      "  size_t tmp___7;\n",
      "  FILE **fps;\n",
      "  size_t nopened;\n",
      "  size_t tmp___8;\n",
      "  FILE *ofp;\n",
      "  FILE *tmp___9;\n",
      "  char *tmp___10;\n",
      "  int *tmp___11;\n",
      "  char *tmp___12;\n",
      "  FILE *tfp___1;\n",
      "  struct tempnode *temp___1;\n",
      "  size_t tmp___13;\n",
      "  size_t tmp___14;\n",
      "\n",
      "\n",
      "Snippet.4:\n",
      "\n",
      "  {\n",
      "    while (1) {\n",
      "\n",
      "      if (!((size_t)nmerge < nfiles)) {\n",
      "        goto while_break;\n",
      "      }\n",
      "      in = (size_t)0;\n",
      "      out = in;\n",
      "      while (1) {\n",
      "\n",
      "        if (!((size_t)nmerge <= nfiles - in)) {\n",
      "          goto while_break___0;\n",
      "        }\n",
      "        tmp = create_temp(&tfp);\n",
      "        temp = tmp;\n",
      "        if (ntemps < (size_t)nmerge) {\n",
      "          tmp___0 = ntemps;\n",
      "        } else {\n",
      "          tmp___0 = (size_t)nmerge;\n",
      "        }\n",
      "        tmp___1 = mergefiles(files + in, tmp___0, (size_t)nmerge, tfp, (char const *)(temp->name));\n",
      "        num_merged = tmp___1;\n",
      "        if (ntemps < num_merged) {\n",
      "          tmp___2 = ntemps;\n",
      "        } else {\n",
      "          tmp___2 = num_merged;\n",
      "        }\n",
      "        ntemps -= tmp___2;\n",
      "        (files + out)->name = (char const *)(temp->name);\n",
      "        (files + out)->temp = temp;\n",
      "        in += num_merged;\n",
      "        out++;\n",
      "      }\n",
      "    while_break___0:\n",
      "      remainder = nfiles - in;\n",
      "      cheap_slots = (unsigned long)nmerge - out % (unsigned long)nmerge;\n"
     ]
    }
   ],
   "source": [
    "print(formatted_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
